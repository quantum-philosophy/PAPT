In this section, the numerical results of the proposed UQ framework for the illustrative example in \sref{illustrative-example} are reported.\footnote{The experiments are conducted on a machine with Intel Core i7 2.66~GHz and 8~GB of RAM.}

The channel length $\Leff$ is assumed to deviate by $5\%$ from the nominal value of 45~nm where the global and local variations are equally weighted \cite{juan2011, juan2012}. Correlation matrices are computed according to \eref{covariance-function}, in which the correlation length $\corrLength$ is half the size of the die. In the model order reduction technique (see \sref{ie-uncertain-parameters}) the threshold parameter $\Lth$ is set to $0.99$ preserving $99\%$ of the variance of the data. Dynamic power profiles involved in the experiments are based on simulations of randomly generated applications defined as directed acyclic task graphs.\footnote{The task graphs of the applications, floorplans of the platforms, configuration of HotSpot, which is used to construct the thermal RC circuits, are available online at \cite{sources}.} The floorplans of the platforms are constructed in such a way that the processing elements form regular grids, as it is the case with, \eg, Alpha 21264 studied in \cite{juan2011}. Time steps of power and temperature traces are set to one millisecond, \ie, $\dt_i = 10^{-3}$~s (see \sref{problem-formulation}). The reference leakage current $I_\leak(\Leff, \T)$ (see \sref{ie-power-model}) is scaled to make the leakage power account for about $40\%$ of the total power at high temperatures \cite{liu2007}. To assess the performance of our framework, we employ a Monte Carlo (MC) sampling technique. For each sample, \ie, for each outcome of the uncertain parameters, the MC approach solves the initial problem in \eref{fourier-system} numerically using the procedure that combines the fourth- and fifth-order Runge-Kutta formulae \cite{press2007}. Based on theoretical estimates \cite{diaz-emparanza2002} of the accuracy of MC, experience from the literature \cite{xiu2010, eldred2009, maitre2010, shen2009}, and our observations, we let the MC approach with $10^4$ samples be the etalon for the evaluation of the proposed UQ framework.

\input{include/assets/accuracy.tex}
The first set of experiments is aimed to identify the accuracy of our framework and, consequently, to find a reasonable value of the polynomial order $\pcorder$ (see \sref{polynomial-chaos}). To this end, three accuracy metrics have been chosen. The first two are the normalized root mean square errors (\nrmses) of expectation and variance of the resulting temperature traces. The third metric is the mean of \nrmses\ of empirical \pdfs\ constructed at each time step for each processing element. The comparison for a quad-core architecture with a dynamic power profile of $\steps = 10^2$ steps is given in \fref{accuracy}, where $\pcorder$ is swept from one to five. It can be seen that the deviation of expectation is small even for $\pcorder = 1$ and is bounded by $0.11\%$. The \nrmse\ of variance starts from $36\%$ for the first-order PC expansion and drops significantly to less than $2\%$ for the third-order PC. The result of the third error estimate, the \nrmses\ of \pdfs, is of particular importance since it allows us to conclude that the \pdfs\ computed by the fourth-order (and higher) PC expansions are closely following those of the MC technique with a large number of samples. Guided by the above observations, we fix the polynomial order $\pcorder$ to four for the rest of the experiments and state that the error of our technique is bounded by less than $0.2\%$ for expectation and less than $2\%$ for variance and \pdf

\input{include/assets/speed.tex}
Now, we focus on the computational speed. First, we vary the number of processing elements $\cores$ and, consequently, the number of \rvs\ $\vars$. In these experiments, the number of time steps $\steps$ is constant and equal to $10^3$. The results are given in \tref{scaling-cores} along with the number of \rvs\ left after KL (see \sref{ie-uncertain-parameters}). It can be seen that the typical symmetric placement and natural radial structure of correlations \cite{cheng2011} open a great possibility for model order reduction. One can also observe a low slope of the execution time of the MC technique, which exhibits the well-known fact that the workload per one MC sample is independent of the number of \rvs\ \cite{maitre2010}. However, even in high dimensions, the proposed framework significantly outperforms MC sampling. For instance, to quantify a power profile with $10^3$ steps of a system with 32 cores, the MC approach requires more than 40 hours whereas the proposed framework takes less than 10 seconds.

Finally, we investigate the scaling properties of the proposed UQ framework with respect to the number of steps $\steps$ of the considered time span. The results for a quad-core architecture are given in \tref{scaling-steps}. Due to the long execution time demonstrated by the MC approach, its computational times for high values of $\steps$ are extrapolated based on a smaller number of samples, \ie, $\mcsamples \ll 10^4$. It can be seen that both methods scale linearly. However, the proposed framework shows a vastly superior performance.
