The probability theory that we shall reside in is defined as a triple $(\outcomes, \sAlgebra, \pMeasure)$ where $\outcomes$ is a set of outcomes, $\sAlgebra \subseteq 2^\outcomes$ is a $\sigma$-algebra on $\outcomes$, and $\pMeasure: \sAlgebra \to [0, 1]$ is a probability measure \cite{durrett2010}. Loosely speaking, an $n$-dimensional \rv\ is then a mapping $\v{X}: \o \in \outcomes \mapsto \v{X}(\o) \in \real^n$. In what follows, the space $(\outcomes, \sAlgebra, \pMeasure)$ is always implied.

Independence of the uncertain parameters is a prerequisite of PC. In general, however, $\vU(\o)$ can be correlated and, therefore, should be preprocessed in order to fulfill the condition. To this end, an adequate probability transformation should be undertaken. Denote such a transformation by $\vU(\o) = \oTransform{\vZ(\o)}$, which relates $\params$ correlated uncertain parameters $\vU(\o)$ with $\vars$ independent \rvs\ $\vZ(\o)$. Without loss of generality, $\vZ(\o)$ are assumed to be centered and normalized, \ie, $\oExp{\vZ(\o)} = \mZero$ and $\oCov{\vZ(\o)} = \mI$.

In this paragraph, we briefly outline a possible strategy of choosing $\oTransform$ and refer the reader to \cite{xiu2010, eldred2009} for in-depth discussions. Correlated \rvs\ that form a Gaussian vector can be transformed to independent ones via a linear mapping based on a factorization procedure of the covariance matrix of $\vU(\o)$; the technique is known as the principal component analysis (PCA) and will be demonstrated in \sref{ie-uncertain-parameters}. In the general case, the most prominent solutions are the Rosenblatt and Nataf transformations \cite{eldred2009}. Rosenblatt's approach is suitable when the joint probability distribution function of the uncertain parameters $\vU(\o)$ is known; however, such information is rarely available. The marginal distributions and correlation matrix of $\vU(\o)$ are more likely to be given, which are sufficient to perform the Nataf transformation.
