% \begin{table}
%   \centering
%   \tlabel{askey}
%   \begin{tabular}{|l|l|l|}
%     \hline
%     & Orthogonal Polynomials & Probability Distribution \\
%     \hline
%     \hline
%     \multirow{4}{*}{Continuous} & Hermite & Gaussian and Log-normal \\
%     & Laguerre & Gamma \\
%     & Jacobi & Beta \\
%     & Legendre & Uniform \\
%     \hline
%     \multirow{4}{*}{Discrete} & Charlier & Poisson \\
%     & Krawtchouk & Binomial \\
%     & Meixner & Negative binomial \\
%     & Hahn & Hypergeometric \\
%     \hline
%   \end{tabular}
%   \caption{The Askey scheme of orthogonal polynomials and the corresponding probability distributions \cite{xiu2002}.}
% \end{table}
At this point, the goal is to transfrom \eref{power-model} in such a way that the non-linear correlations in the recurrence given by \eref{recurrence} are eliminated. To this end, we empoly the generalize polynomial chaos (gPC) \cite{xiu2002}, which deconstructs stochastic processes into infinite sequences of \emph{orthogonal} polynomials of r.v.'s. The orthogonality of a set of polynomials $\{ \pcb_i(\virv) \}$ is defined as
\begin{equation} \elabel{orthogonality}
  \oInner{\pcb_i(\virv) \pcb_j(\virv)} = \oInner{\pcb_i(\virv)^2} \delta_{ij}
\end{equation}
where $i,j \in \natural{0}$, $\delta_{ij}$ is the Kronecker delta function, and the operator $\oInner{\cd}$ denotes the inner product in the Hilbert space spanned by the polynomials. The inner product with the weight function $\pdf(\virv)$ is defined as the following multi-dimensional integral:
\begin{equation} \elabel{inner-product-integral}
  \oInner{f(\virv) g(\virv)} \eqdef \int f(\virv) g(\virv) \pdf(\virv) d\virv
\end{equation}
when $\pdf(\virv)$ is continuous, or as the following summation:
\begin{equation} \elabel{inner-product-sum}
  \oInner{f(\virv) g(\virv)} \eqdef \sum f(\virv) g(\virv) \pdf(\virv)
\end{equation}
when $\pdf(\virv)$ is discrete. In our case, the weight function corresponds to the probability density (continuous) or mass (discrete) function $\pdf_\vIRV(\virv)$ of the r.v.'s $\vIRV(\o)$, and the inner product is the expectation operator. Therefore, it can be seen from \eref{orthogonality} that the orthogonality is equal to the absence of correlations, and this is, in fact, what we seek for. Consequently, we apply the gPC expansion to the power term, $\vP(t, \o)$, in the thermal model given by \eref{fourier-system} since it is the source of uncertainties.

The first step towards a gPC expansion is the choice of a suitable polynomial basis $\{ \pcb_i(\vIRV(\o)) \}$ according to the Askey scheme of orthogonal polynomials, which can be found in \cite{xiu2002}. The step is crucial due to the following reason. In spite of the fact that the PC/gPC expansion is guaranteed to converge in $\L{2}$, the rate of convergence essentially depends on the chosen basis. Since the expansion should be truncated (to become feasible for the practical computations), an inappropriately selected basis can lead either to a low accuracy or to a large number of terms of the expansion ruining the performance. There are no strict rules that can guarantee the optimal choice, however, there are best practices saying that the choice should be governed by the underlying r.v.'s., which drive the stochastic system. For instance, the Hermite polynomials are suitable for normally distributed r.v.'s while the Charlier polynomials are preferable for Poisson variations\footnote{We refer the reader to \cite{xiu2002} for the other combinations.}. It is worth being mentioned that the major sources of uncertainties due to the process variation, such as the channel length, threshold voltage, gate oxide thickness, etc., are generally accepted to have a Gaussian distribution \cite{srivastava2010, liu2007, juan2012}, therefore, the Hermite basis is of a particular interest.

Once an appropriate basis has been chosen, the next step is to actually perform the gPC expansion of the power term in \eref{ode-solution} defined as
\begin{equation} \elabel{pc-expansion}
  \oPC{\vars}{\pcorder}{\vP(0, \o)} \eqdef \sum_{i = 1}^{\pcterms} \pcc{\vP}_i(0) \; \pcb_i(\vIRV(\o))
\end{equation}
where $\pcc{\vP}_i(0) \in \real^\cores$ are the coefficients of the expansion. $\pcorder \in \natural{0}$ is the order of the expansion, which determines the maximal (total) degree of the $\vars$-variate polynomials involved in the expansion. Consequently, $\pcorder$ also defines the level of accuracy of the resulting model. The number of terms in the expansion, $\pcterms$, can be computed as $\pcterms = {\pcorder + \vars \choose \pcorder}$.

Finally, we need to determine the coefficients of the expansion $\pcc{\vP}_i(0)$, $i \in \{ 1, \dotsc, \pcterms \}$. To this end, the stochastic process (\eref{power-model}) is projected onto the space spanned by the finite set of orthogonal polynomials $\{ \pcb_i(\vIRV(\o)) \}_{i = 1}^{\pcterms}$. The procedure is known as a Galerkin projection where one needs to compute the inner product of the governing equation \eref{power-model} with each polynomial from the basis as
\[
  \oInner{\sum_{i=1}^{\pcterms} \pcc{\vP}_k(0) \pcb_i(\vIRV(\o)) \pcb_k(\vIRV(\o))} = \oInner{\vP(0, \o) \; \pcb_k(\vIRV(\o))}
\]
where $k \in \{ 1, \dotsc, \pcterms \}$. Making use of the orthogonality property given by \eref{orthogonality}, we obtain
\begin{equation} \elabel{pc-coefficients}
  \pcc{\vP}_k(0) = \frac{\oInner{\vP(0, \o) \; \pcb_k(\vIRV(\o))}}{\oInner{\pcb_k(\vIRV(\o))^2}}
\end{equation}
for $k \in \{ 1, \dotsc, \pcterms \}$. The numerator of \eref{pc-coefficients} is multi-dimensional integrals given by \eref{inner-product-integral}. In general, the evaluation should be done numerically as it is further discussed in \sref{integration}. The denominator is also a multi-dimansional integral; however, it is fixed for a particular polynomial basis. Hence, the normalization constants $\oInner{\pcb_k(\vIRV(\o))^2}$, $i \in \{ 1, \dotsc, \pcterms \}$, are usually precomputed and tabulated; see \cite{ghanem1991}.

Using \eref{pc-expansion}, the recurrence given by \eref{recurrence} is rewritten as follows:
\[
  \vX_i(\t, \o) = \mE(\t) \vX_i(0, \o) + \mD(\t) \; \oPC{\vars}{\pcorder}{\vP_i(0, \o)}
\]
where $\t \in [0, \dt_i]$. It can be see that, due to the linearity of the operations involved in the recurrence, the state vector $\vX_i(\t, \o)$ retains the same polynomial structure as the input vector of power at each step of the iterative process. Therefore,
\[
  \oPC{\vars}{\pcorder}{\vX_i(\t, \o)} = \mE(\t) \; \oPC{\vars}{\pcorder}{\vX_i(0, \o)} + \mD(\t) \; \oPC{\vars}{\pcorder}{\vP_i(0, \o)}
\]
where there are two gPC expansions for two cuncurrent stochastic processes with the same basis, but different coefficients. The left- and right-hand sides of the last equation can be explicitely rewritten as
\begin{align*}
  & \text{LHS} = \sum_{i = 1}^{\pcterms} \pcc{\vX}_i(\t) \pcb_i(\vIRV(\o)) \\
  & \text{RHS} = \sum_{i = 1}^{\pcterms} \left( \mE(\t) \pcc{\vX}_i(0) + \mD(\t) \pcc{\vP}_i(0) \right) \pcb_i(\vIRV(\o))
\end{align*}
By the orthgonality property of the polynomials $\{ \pcb_i(\vIRV(\o)) \}_{i = 1}^{\pcterms}$ given by \eref{orthogonality}, we have
\begin{equation} \elabel{pc-recurrence}
  \pcc{\vX}_k(\t) = \mE(\t) \pcc{\vX}_k(0) + \mD(\t) \pcc{\vP}_k(0)
\end{equation}
The recurrence given by \eref{pc-recurrence} is used to compute the coefficients of the gPC expansion of temperature based on the coefficients of the gPC expansion of power, since between the actual temperature $\vTO(\t, \o)$ and the state vector $\vX(\t, \o)$ there is only one step given by \eref{fourier-output}.

One should not forget that $\vP(0, \o)$ stands for $\vP(0, \vTO(0, \o), \o)$. Therefore, at each step of the iterative process given by \eref{pc-recurrence}, the computation of $\pcc{\vP}_k(0)$ (according to \eref{inner-product-integral} or \eref{inner-product-sum}) is performed with respect to the (current) gPC expansion of $\vTO(0, \o)$.
