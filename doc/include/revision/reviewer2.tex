\begin{reviewer}
Using polynomial chaos (PC) approach to capture process variation caused performance issues in VLSI design was first pointed out and developed by authors from [5][17][18]. And it really works well ! Most theoretical part of this paper followed similar derivations as these previous papers. However, comparing with Monte Carlo based approaches, PC may end up doing  lengthy  coefficients solving procedure. No surprise that the authors need additional surrogate modeling and multi-processors to deal with the speedup.

This paper is well written overall.
\end{reviewer}
\begin{authors}
Thank you.
\end{authors}

\begin{reviewer}
My major concerns are in the experimental results part.

1) The authors used 45nm technology node. But the variation is only 5\%. Is this too low ? Of course variations depend on fab. Different companies may provide different number. But isnt this should be around 30\% to 50\% on average.
\end{reviewer}
\begin{authors}
We would like to begin by noting that our framework is not constrained by any particular value of the standard deviation, denoted by $\sigma$, of the divergence of the effective channel length from the nominal value, denoted by $\mu$.
The scenario with a 45-nm technological process and $\sigma$ equal to 5\% of $\mu$ is only an example, which was taken from the literature [Juan, 2011, 2012].
Let us give several other examples.
[Shen, 2009] considers a 45-nm process and sets $\sigma$ to 4\% of $\mu$.
[Chandra, 2010] addresses a 90-nm process with $\sigma$ equal to $10\%$ of $\mu$.
[Bhardway, 2008] use a 90-nm process and $\sigma$ of 3.33\% of $\mu$.
Please also consider the fifth comment of Reviewer 3.

The high percentages mentioned by the reviewer typically appear in the context where the portion of a particular type of variability is compared to the total variation.
For example, Fig.~6.1 on page 98 in [Chandrakasan, 2000] shows ``the percentage of the total variation accounted for by within-die variation,'' and the maximal percentage there indeed goes up to 50\%.

\begin{actions}
  \action{The formulation regarding the variability of the effective channel length has been updated at the beginning of Sec.~VII.}
\end{actions}
\end{authors}

\begin{reviewer}
2) It is not very clear how big the size of the circuits or designs we are looking at.
As far as i known, most papers referenced do have fairly big size examples and circuits. Matlab code unfortunately may not be able to handle such big examples.
But without large size of examples, the scaling up numbers in the tables in this paper are more or less like speculations.
\end{reviewer}
\begin{authors}
We would like to clarify that the power/temperature modeling in the paper is at the system level, not at the circuit level.
Please consider our answer to the second comment of Reviewer 1.

As described in Sec.~VI-B, the leakage model used in the illustrative example is based on SPICE simulations of a reference electrical circuit.
The circuit that we use is a series of CMOS invertors, kindly provided to us by the people acknowledged at the end of the main part of the manuscript.
Regarding the thermal modeling, we exemplify our framework using the block model of HotSpot v5.02 with a one-to-one mapping between the processing elements and thermal nodes (mentioned in Sec.~V-C).
In this case, the considered setups with 2--32 processing elements translate into 20--140 thermal nodes (the relation is $\nnodes = 4 \, \nprocs + 12$ given in Sec. VI-C).
Therefore, the performed calculations are doable for MATLAB running on a personal laptop.

\begin{actions}
  \action{The system-level scope of the paper has been emphasized in Sec.~IV, which also addressed the second comment of Reviewer 1.}
  \action{The reference electrical circuit has been described in Sec.~VI-B.}
\end{actions}
\end{authors}

\begin{reviewer}
3) If thermal and power are the key concerns of this paper, it probably makes sense to compare this work with existing papers (i.e. [5][17][18]).
\end{reviewer}
\begin{authors}
The reviewer mentioned two types of papers: deterministic ([Rao, 2009]\footnote{The authors of [Rao, 2009] develop a predictor of the steady-state throughput and power dissipation without considering process variation.}) and stochastic ([Bhardwaj, 2006] and [Ghanta, 2006]).
Let us discuss each type separately.

The absence of a comparison with deterministic techniques is motivated by the fact that our work is dedicated to probabilistic analysis; therefore, such a comparison is outside of the scope of the manuscript.
However, we would like to note that our thermal model \perse\ (\ie, the construction of equivalent RC thermal circuits) is well established and has numerous justifications in the corresponding literature.
In relation to [Rao, 2009], the temperature analysis in that paper is drastically different from the one considered here: it is static steady state while we address the transient scenario.
The drawbacks of the static steady-state assumption are illustrated and discussed in detail in [Ukhov, 2012] wherein a reference to [Rao, 2009] is also included.
Moreover, [Rao, 2009] makes four additional assumptions (see Sec.~III-A in that paper) and severely mangles the original thermal model taken from HotSpot; none of this assumptions is present in our work.
Therefore, our thermal model is more exact by definition.
Finally, the leakage modeling, which is based on the data from SPICE simulations, is also a rather common approach frequently encountered in the literature; see, \eg, [Bhardwaj, 2006] and [Ghanta, 2006].

Let us turn now to the absence of a comparison with probabilistic solutions to power.
As mentioned in Sec.~II, [Bhardwaj, 2006] and [Ghanta, 2006] perform power analysis without taking into account the important interdependence between leakage and temperature.
Thus, a direct comparison with the power part of our stochastic power-temperature analysis cannot be drawn.
In addition, despite the fact that the proposed framework covers both power and temperature, we initiated this work aiming to the quantification of temperature, not power \perse\ as it had already been addressed by other researchers.
Our main focus was always on temperature, and power is a side effect, although essential, on the way to temperature.
Therefore, the experimental results are primarily dedicated to temperature, which makes the main contribution of our research.

We would like to comment also on potential comparisons with temperature-targeted techniques.
The most relevant works, from our perspective, and their limitations are discussed in Sec.~II.
Since we address the transient scenario while others work under the steady-state assumption (and one of them, in addition, is limited to the maximal temperature), a one-to-one comparison is not possible.

\begin{actions}
  \action{The absence of comparisons with prior techniques has been explained in Sec.~VII.}
\end{actions}
\end{authors}
