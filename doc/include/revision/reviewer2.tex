\begin{reviewer}
Using polynomial chaos (PC) approach to capture process variation caused performance issues in VLSI design was first pointed out and developed by authors from [5][17][18]. And it really works well ! Most theoretical part of this paper followed similar derivations as these previous papers. However, comparing with Monte Carlo based approaches, PC may end up doing  lengthy  coefficients solving procedure. No surprise that the authors need additional surrogate modeling and multi-processors to deal with the speedup.

This paper is well written overall.
\end{reviewer}
\begin{authors}
Thank you.
\end{authors}

\begin{reviewer}
My major concerns are in the experimental results part.

1) The authors used 45nm technology node. But the variation is only 5\%. Is this too low ? Of course variations depend on fab. Different companies may provide different number. But isnt this should be around 30\% to 50\% on average.
\end{reviewer}
\begin{authors}
Our framework is not constrained by any particular value of the standard deviation, denoted by $\sigma$, of the divergence of the effective channel length from the nominal value, denoted by $\mu$.
The scenario $\mu = 45~\text{nm}$ and $\sigma$ is 5\% of $\mu$ is only an example, which was taken from the literature [D.-C. Juan \etal, 2011, 2012].
To give another example, [R. Shen \etal, 2009] also considers a 45-nm technological process wherein $\sigma$ is equal to 4\% of $\mu$.
In [S. Chandra \etal, 2010], the authors consider a 90-nm process and use $\sigma$ equal to $10\%$ of $\mu$.
The high percentages mentioned by the reviewer typically appear in the context where the portion of a particular type of variability is compared to the total variation.
Please refer to, \eg, [A. Chandrakasan, 2000], Fig.~6.1 on page 98, wherein ``the percentage of the total variation accounted for by within-die variation [\ldots] is plotted,'' and the maximal percentage indeed goes up to 50\%.

\done{The formulation regarding the variability of the effective channel length has been updated in Sec.~VII, which also brought attention of Reviewer 3 in the fifth comment.}
\end{authors}

\begin{reviewer}
2) It is not very clear how big the size of the circuits or designs we are looking at.
As far as i known, most papers referenced do have fairly big size examples and circuits. Matlab code unfortunately may not be able to handle such big examples.
But without large size of examples, the scaling up numbers in the tables in this paper are more or less like speculations.
\end{reviewer}
\begin{authors}
The power/temperature modeling considered in the paper is at the system level, not at the circuit level.
As described in Sec.~VI-B, the leakage model used in the illustrative example is based on SPICE simulations of a reference electrical circuit.
The circuit that we use is a series of CMOS invertors, kindly provided to us by the people acknowledged at the end of the main part of the manuscript.
Regarding the thermal modeling, we exemplify our framework using the block model of HotSpot v5.02 with a one-to-one mapping between the processing elements and thermal nodes (mentioned in Sec.~V-C).
In this case, the considered setups with 2--32 processing elements translate into 20--140 thermal nodes (the relation is $\nnodes = 4 \times \nprocs + 12$ given in Sec. VI-C).
Therefore, the performed calculations are doable for MATLAB running on a personal laptop.
It is worth noting that the one-to-one mapping is used merely for the clarity of the discussions in the paper, and this mapping can be arbitrary, depending on the desired level of accuracy.

\done{The system-level scope of the paper has been emphasized in Sec.~IV, which also addressed the second comment of Reviewer 1.}

\done{The reference electrical circuit has been described in Sec.~VI-B.}
\end{authors}

\begin{reviewer}
3) If thermal and power are the key concerns of this paper, it probably makes sense to compare this work with existing papers (i.e. [5][17][18]).
\end{reviewer}
\begin{authors}
The reviewer mentioned two types of papers: deterministic ([R. Rao \etal, 2009]) and stochastic ([S. Bhardwaj \etal, 2006] and [P. Ghanta \etal, 2006]).
The absence of a comparison with deterministic techniques is motivated by the fact that our work is dedicated to probabilistic analysis; therefore, such a comparison is outside of the scope of the manuscript.
However, we would like to note that our thermal model \perse\ (\ie, the construction of equivalent RC thermal circuits) is well established and has numerous justifications in the corresponding literature.
The accuracy of the solution process described in App.~A has also been assessed not only by us, [I. Ukhov \etal, 2012], but also by other groups of researchers such as [L. Thiele \etal, 2011].
In relation to [R. Rao \etal, 2009], the temperature analysis in that paper is drastically different from the one considered here: it is static steady state while we address the transient scenario.
The drawbacks of the static steady-state assumption are illustrated and discussed in detail in [I. Ukhov \etal, 2012] wherein a reference to [R. Rao \etal, 2009] is also present.
Moreover, [R. Rao \etal, 2009] makes four additional assumptions (see Sec.~III-A in that paper) and severely mangles the original thermal model taken from HotSpot; none of this assumptions is present in our work.
Therefore, by definition, our thermal model is more exact.
Finally, the leakage modeling using SPICE simulations is also a frequently encountered approach; see, \eg, [D.-C. Juan \etal, 2011, 2012].

Let us now turn to the absence of a comparison with stochastic techniques.
As mentioned in Sec.~II, [S. Bhardwaj \etal, 2006] and [P. Ghanta \etal, 2006] perform stochastic power analysis without taking into account the important interdependence between leakage and temperature.
Hence, a direct comparison with our temperature-aware solution cannot be drawn.
In addition, while [P. Ghanta \etal, 2006] does employs PC expansions, [S. Bhardwaj \etal, 2006] is based solely on the KL decomposition, which further hinders a direct comparison with our approach.
Finally, despite the fact that the proposed framework covers both power and temperature, we initiated this work aiming to the quantification of temperature, not power alone as it had already been addressed by other researchers.
In other words, our main focus was always on temperature, and power is a byproduct on the way to temperature if you will.
Therefore, the experimental results are primarily dedicated to stochastic temperature analysis, which makes the main contribution of our research.
Now, regarding potential comparisons with temperature-targeted techniques, the most relevant, from our perspective, works and their limitations are discussed in Sec.~II.
Since we address the transient scenario while others either address the maximal or work under the steady-state assumption, a one-to-one comparison is not possible.

\done{The absence of comparisons with prior techniques has been explained in Sec.~VII.}
\end{authors}
