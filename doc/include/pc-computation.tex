In the current scenario, the generalized PC expansion is to be founded on the Hermite polynomial basis since it is the optimal choice for $\vZ(\o) \sim \normal{\vZero}{\mI}$ \cite{xiu2002}. To illustrate the basis, in the two-dimensional case the first Hermite polynomials $\pcb_i(\{ \Z_1(\o), \Z_2(\o) \})$ are
\[
  \begin{array}{lllllll}
  1, & \Z_1, & \Z_2, & \Z_1^2 - 1, & \Z_1 \Z_2, & \Z_2^2 - 1, & \dotsc
  \end{array}
\]
The goal now is to compute the coefficients of the power expansion in \eref{pc-expansion}, which should be done according to \eref{inner-product-integral} since the Gaussian distribution is continuous.

In numerical integration, an integral of a function is approximated by a weighted sum of the function (integrand) values evaluated at certain points known as nodes. A particular scheme to choose nodes and weights is called a \definition{quadrature rule}. A one-dimensional quadrature rule is characterized by its order and precision. The order $\qdorder \in \natural{1}$ is the number of nodes employed in the rule whereas the precision $\qdprecision \in \natural{0}$ is the maximal order of polynomials that the rule integrates \emph{exactly}. A rule forms a family, which is defined as an indexed set of rules of this kind with increasing precision. The index of a rule with a particular precision in its family is known as the level (of accuracy) $\qdlevel \in \natural{0}$.

In multiple dimensions, multivariate quadrature rules are needed. One way to construct such rules is to use the tensor product of one-dimensional quadrature rules. In this case, the total number of nodes, which is the order of the new rule, is $\qdorder^\vars$ where $\vars$ is the number of dimensions. However, the precision $\qdprecision$ stays the same, i.e., the rule is exact for multivariate polynomials of \emph{total} order not greater than $\qdprecision$. Consequently, in a multidimensional scenario, the number of nodes can easily explode even for low precision requirements. Moreover, if the integrand is a complete polynomial\footnote{A complete polynomial is a multivariate polynomial with a bounded \emph{total} order \cite{heiss2008}.}, most of the nodes in the tensor product are wasted in the sense that they do not contribute to the resulting accuracy \cite{heiss2008}. Therefore, multivariate quadrature rules based on the tensor product are efficient only in low dimensions; in high dimensions they are often infeasible. Therefore, deliberately constructed integration grids of sparse structures for high dimensions are desired.

One of the most successful and wide-spread technique to construct a sparse grid was proposed by Sergey Smolyak in 1963 and is known now by his name. Given a family of one-dimensional quadrature rules, the Smolyak algorithm constructs a multidimensional grid in such a way that the accuracy of the underlying rules is preserved for complete polynomials whereas the number of nodes in the grid is significantly smaller than those of the tensor product \cite{heiss2008, eldred2009}. For instance, if a one-dimensional rule requires only 3 nodes to integrate exactly the fifth-order polynomials, then in 20 dimensions the number of nodes according to the tensor product should be in the order of $10^9$. However, the same accuracy can be achieved having only 841 nodes determined by the Smolyak technique. Hence, the algorithm efficiently mitigates the ``curse of dimensionality'' mentioned in \sref{polynomial-chaos}. We refer the reader to \cite{eldred2009, maitre2010, heiss2008} for further discussions on the Smolyak algorithm.

Since in the illustrative example under consideration, we need to compute expectations (integrals) with respect to the Gaussian measure, one quadrature rule is of a particular interest for us. The rule is known as the Gauss-Hermite quadrature rule where the nodes are the roots of the Hermite polynomials and the weight function corresponds to the Gaussian probability density function. The rule belongs to Gaussian quadrature rules where the order $\qdorder$ and precision $\qdprecision$ are related as $\qdprecision = 2 \qdorder - 1$ making Gaussian quadratures especially efficient \cite{heiss2008}. Using the family of one-dimensional Gauss-Hermite quadrature rules and either the tensor product for low dimensions or the Smolyak algorithm for high dimensions, the $\vars$-variate quadrature rule of accuracy level $\qdlevel$ can be constructed. Define the rule as
\[
  \oQuad{\vars}{\qdlevel}{f} \eqdef \sum_{i = 1}^{\qdorder} f(\qdn{\vZ}_i) \qdw_i
\]
where $\qdorder$ is the order of the multivariate rule, $\qdn{\vZ}_i \in \real^\vars$ and $\qdw_i \in \real$ are the prescribed nodes and weights, respectively. The nodes are $\vars$-dimensional vectors, which corresponds to the number of uncertain parameters $\vZ(\o)$. The level of accuracy $\qdlevel$ should be chosen in such a way that the quadrature rule is exact for polynomials of order $2 \pcorder$ (twice the order of the PC expansion), which can be seen in \eref{pc-coefficients}. Therefore, $\qdlevel = \pcorder + 1$ according to the property of Gaussian quadratures discussed earlier. Consequently, \eref{pc-coefficients} is rewritten as
\[
  \pcc{\vP}_i(0) = \frac{1}{\pcn_i} \oQuad{\vars}{\qdlevel}{\vP(0, \o) \pcb_i(\vZ(\o))}
\]
where $\{ \pcn_i \}_{i = 1}^{\pcterms}$ are computed \emph{exactly} either by directly using the same quadrature rule or by taking products of one-dimensional counterparts with known analytical expressions \cite{xiu2010}; the result is further tabulated.
