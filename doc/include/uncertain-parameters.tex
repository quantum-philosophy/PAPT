Stochastic systems are often naturally parametrized with a set of independent r.v.'s where dependent quantities, if any, have been replaced with functions of independent ones \cite{xiu2009}. In general, however, the uncertain parameters $\vU(\o)$ can be correlated and should be preprocessed to extract a set of \emph{mutually independent} r.v.'s. To this end, depending on the available information, certain probability transformations should be undertaken. We outline a possible strategy in brief and refer the reader to \cite{eldred2009, xiu2009} for more detailed discussions.

Linear correlations between r.v.'s can always be removed by means of a linear transformation based on a factorization procedure of the covariance matrix of $\vU(\o)$. For instance, the Cholesky, singular value, eigenvalue decompositions \cite{press2007} are suitable for this purpose as we demonstrate in \sref{illustrative-example}. If $\vU(\o)$ are distributed normally, the absence of correlations is equal to independence, and the preprocessing stage finishes at this point. In the non-normal case, nonlinear transformations are commonly used. When the data are nearly normal, such transformations as the Box-Cox transformation \cite{box1964} can take place to straighten the normality assumption and apply the previous technique. In the general case, the most prominent solutions are the Rosenblatt \cite{rosenblatt1952} and Nataf \cite{hongshuang2008} transformations. Rosenblatt's approach is suitable when the joint probability distribution function of $\vU(\o)$ is known; however, such information is rarely available, and the marginal distributions and correlation matrix of $\vU(\o)$ are more likely to be given. These data are sufficient to perform the Nataf transformation where $\vU(\o)$ are transferred from the initial probability space to the space of normal r.v.'s, in which the correlations of $\vU(\o)$ are properly preserved, and then the result is exposed to the linear transformation described earlier to remove the correlations and finalize the process.

In the rest of the paper, $\vZ(\o) = \oTransform{\vU(\o)}$ denotes the vector of $\vars$ independent r.v.'s that have been extracted from $\vU(\o)$ using an appropriate transformation $\oTransform{\idot}$. Also, without loss of generality, we assume that $\vZ(\o)$ is centered and normalized by the operator\footnote{$\oExp{\vZ(\o)} = \mZero$ and $\oCov{\vZ(\o)} = \mI$.}. Denote the inverse transformation by $\oInvTransform{\idot}$; then in the following $\oInvTransform{\vZ(\o)}$ is assumed to be used in the place of $\vU(\o)$. For brevity, we shall not write explicitly $\oInvTransform{\vZ(\o)}$ and use $\vZ$ or just $\o$ instead. Let $(\outcomes, \sAlgebra, \pMeasure)$ be the corresponding probability space and $\PDF_\vZ(\vz)$ be the joint probability density (mass) function of $\vZ(\o)$ associated with the continuous (discrete) measure $\pMeasure$.
