Over the last decade the concept of uncertainty quantification (UQ) has drawn a lot of attention in an astonishingly comprehensive range of research areas \cite{xiu2009}. The primary target of UQ techniques is the evaluation of the output of the systems that exhibit a non-deterministic behaviour due to an internal/external interference of uncertainties of some kind \cite{eldred2009}. The reason for this rapid growth of interest is clear --- the capacity of idealized models, in which everything is assumed to be purely deterministic, have been entirely depleted by the ever demanding technological progress. The results of such models are no longer acceptable as they inherently lack an essential portion of reality, viz. its random nature.

Multiprocessor platforms, as regular physical systems at the first place, are not delivered from the fate of uncertainty. Often variability is connatural and unavoidable; the uncertainties due to the semiconductor manufacturing process and operating environment are the most prominent examples. Consequently, the fabrication of robust products requires a proper modeling of these immanent variations at early design stages.

One of the major concerns of multiprocessor architects are temperature and its close counterpart power. In the contemporary literature, one can notice that most of the studies that involve thermal modeling, both steady-state and transient, are based on deterministic solutions where the input parameters are assumed to be constant, e.g., \cite{ukhov2012}. However, the reliability of such estimates can be questionable in practice due to the negligence of the above-mentioned variability. Sequentially, the overall quality of frameworks based on the deterministic temperature analysis (TA) can be severely deteriorated.

To overcome the outlined limitation of the deterministic TA, the stochastic TA is to be developed. A number of such techniques have been recently introduced. In \cite{juan2011}, a learning-based approach is presented to estimate the maximal steady-state temperature of 3D ICs under the variability of the leakage power. Another procedure to account for the uncertainties of leakage is proposed in \cite{juan2012} where a statistical model of the steady-state temperature based on the Gaussian distribution and the Box-Cox transformation \cite{box1964} is derived. It should be noted that the aforementioned techniques are narrowly targeted at specific problems, namely, they aim to quantify the maximal temperature under the necessarily \emph{steady-state} condition. The second approach is, moreover, tailored for Gaussian or nearly Gaussian variations of the power dissipation. However, when the knowledge of the transient temperature is desired, or the steady-state assumption cannot be safely accepted, the stochastic transient TA is to be performed, which constitutes a (much) more difficult goal to achieve.

The most straight-forward way to perform the stochastic TA of any kind is to employ a Monte Carlo (MC) sampling technique coupled with a deterministic thermal simulator. MC-based approaches possess a few unique features, which make them preferable for certain situations. First, such techniques are easy to implement since existing deterministic solves can be readily employed without any modifications. Secondly, and more importantly, the MC sampling is insensible to the number of stochastic dimensions \cite{maitre2010}; therefore, MC techniques can be advantageous for systems that involve large numbers of random variables. However, the major problem with the MC sampling is in the low rate of convergence, e.g., the mean value is known to converge as $\mcsamples^{-\ifrac{1}{2}}$ where $\mcsamples$ is the number of samples \cite{xiu2009, maitre2010}. One sample in this case is a complete realization of the whole thermal system, which makes MC-based methods slow and often infeasible to undertake provided that the number of such simulations should be considerably high (in the order of $10^4$) to obtain representative results.

Attractive alternatives to the MC sampling are spectral methods \cite{maitre2010}, which demonstrate much faster convergence rates, and one of these methods is the subject of this paper. Namely, we use a probabilistic framework called the polynomial chaos (PC), which constitutes the current state of the art of numerical analysis of stochastic systems \cite{xiu2009}. The PC is especially valuable for the purpose of UQ due to its strong mathematical background and ability to construct \emph{analytical} representations of uncertain quantities \cite{eldred2009}. To elaborate, the core of the PC is the decomposition of stochastic processes into infinite sums of orthogonal polynomials of random variables. It can be shown that \emph{any} functional with a finite variance can be approximated with such a PC expansion, and this expansion converges in the $\L{2}$ (mean-square) sense. Once constructed, PC series are essentially easy to be analyzed from different perspectives. As an example, global and local sensitivity analyses of probabilistic and non-probabilistic parameters can be readily applied to a PC expansion \cite{eldred2009, maitre2010}.

Spectral methods have been successfully employed to quantify an ample range of diverse stochastic systems \cite{xiu2010}. As it is noted earlier, within the area of computer systems, much attention has been devoted to the leakage modeling. In \cite{bhardwaj2006}, the authors use the Karhunen-Lo\`{e}ve (KL) expansion \cite{loeve1978} to estimate leakage of electrical circuits based on covariance functions of process parameters. In \cite{shen2009}, the full-chip leakage estimation is achieved by means of the PC expansion with the Hermite polynomials. The analysis of large power grids aimed to characterize the voltage response is carried out in \cite{ghanta2006} where the KL and Hermite PC expansions are used.

In this work, we utilize the PC to quantify power and the resulting temperature of stochastic multiprocessor systems. To illustrate the proposed framework, we apply our technique to a particular problem. To be exact, we have also chosen to address the leakage power subjected to the process variation since, as previously mentioned, it is one of the major concerns of the multiprocessor system design. In this case, the stochastic TA is complicated by the following facts. First of all, the leakage current has a nonlinear dependency structure on the intrinsic fabrication parameters, which are uncertain due to the imperfection of the semiconductor manufacturing process, cf. \cite{juan2011, juan2012, srivastava2010}. Secondly, the leakage power and temperature have a strong, nonlinear interdependency \cite{liu2007}, which makes the goal of the stochastic TA even more challenging. Nevertheless, the proposed framework shows efficiency and accuracy in solving such problems as it is verified by a MC sampling technique.

The rest of the paper is organized as follows. \sref{preliminaries} overviews the basic notations used here and introduces the architecture model that we shall consider. In \sref{problem-formulation}, we briefly outline the problem that we aim to solve. The proposed framework is presented in \sref{proposed-framework}. \sref{illustrative-example} illustrates our technique on an example with the leakage power. Numerical results in terms of computational speed and accuracy are given in \sref{experimental-results} where a comparison with a MC-based technique is drawn. Finally, \sref{conclusion} concludes the paper.
