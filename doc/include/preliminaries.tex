Throughout this article, we use the following notations. $\real$ and $\natural$ are the sets of real numbers and nonnegative integers, respectively. Boldface letters denote vectors and matrices, e.g., $\m{M} = \mtx{m_{ij}} \in \real^{n \times m}$ denotes a $n \times m$ real matrix, and $\v{V} = \vec{v_i} \in \real^n$ denotes and an $n$-dimensional real column vector. $\m{M}^T$ and $e^\m{M}$ are the transpose and matrix exponential of $\m{M}$, respectively. $\diag{m_i} \in \real^{n \times n}$ denotes a $n \times n$ diagonal matrix. $\mI_n$ is the $n \times n$ identity matrix, and $\mZ_{n \times m}$ is the $n \times m$ zero matrix; we shall omit these indexes when the actual dimensions of $\mI$ and $\mZ$ are clear from the context. Finaly, $\sI_n = \{ 0, \dots, n - 1 \} \subset \natural^n$ denotes the set of first $n$ natural numbers.

Let $(\outcomes, \sAlgebra, \pMeasure)$ be a complete probability space \cite{durrett2010} where $\outcomes$ is a set of outcomes, $\sAlgebra$ is a $\sigma$-algebra on $\outcomes$, and $\pMeasure$ is a probability measure induced on the measurable space $(\outcomes, \sAlgebra)$. A $\sAlgebra$-measurable function $\rv{x}(\o): \outcomes \to \real$ is called a \definition{random variable} (r.v.). Denote $\exp_\rv{x} = \oExp{\rv{x}(\o)}$ the expectation of $\rv{x}(\o)$ and $\var_\rv{x} = \oVar{\rv{x}(\o)}$ its variance. A $\pMeasure$-measurable, vector-valued function $\mrv{x}(\o): \outcomes \to \real^n$ is called a multivariate random variable (m.r.v.) with $\vExp_\mrv{x} = \oExp{\mrv{x}(\o)}$ and $\mCov_\mrv{x} = \oCov{\mrv{x}(\o)}$ being its expectation vector and covariance matrix, respectively. A \definition{stochastic process} is a parametrized collection of r.v.'s $\{ \rv{x}(\o, \t) \}_{\t \in \sTime}$ where $\sTime$ is a parameter space, which is usually assumed to be the real half line $[0, \infty)$ meaning time. $\{ \mrv{x}(\o, \t) \}_{\t \in \sTime}$ denotes a $n$-dimensional stochastic process. We shall omit the argument $\o \in \outcomes$ when the stochastic nature of the quantity under consideration is clear from the context.

The covariance matrix $\mCov_\mrv{x}$ is necessarily a real symmetric matrix. Therefore, it can be decomposed into the product $\mCov_\mrv{x} = \m{U}_{\mCov_\mrv{x}} \m{V}_{\mCov_\mrv{x}} \m{U}_{\mCov_\mrv{x}}^T$ using the eigenvalue decomposition \cite{press2007} where $\m{U}_{\mCov_\mrv{x}}$ and $\m{V}_{\mCov_\mrv{x}}$ are an orthogonal matrix of the eigenvectors and a diagonal matrix of the eigenvalues of $\mCov_\mrv{x}$, respectively. Define the operator $\oEigen{\cd} = \m{U}_{(\cd)} {\m{V}_{(\cd)}}^{1/2}$. Consequently, a m.r.v. $\mrv{x}$ can be normalized as $\mrv{x} = \oEigen{\mCov_\mrv{x}} \mrv{y} + \vExp_\mrv{x}$ where $\vExp_\mrv{y} = \mZ$ and $\mCov_\mrv{y} = \mI$.
